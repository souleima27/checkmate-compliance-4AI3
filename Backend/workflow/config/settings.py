"""
Configuration centralis√©e pour le syst√®me de v√©rification de conformit√©
"""

import os

# ====================  CHEMINS DES FICHIERS ====================
# Utilisation de chemins relatifs pour la portabilit√©

# Base dir: inside Backend/workflow
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
PROJECT_ROOT = os.path.dirname(BASE_DIR) # Backend/

# Dossiers de sortie
OUTPUT_DIR = os.path.join(BASE_DIR, "output")
LOGS_DIR = os.path.join(BASE_DIR, "logs")
CACHE_DIR = os.path.join(BASE_DIR, "caches")

# R√®gles de conformit√©
REGLES_CONTEXTUELLES_PATH = os.path.join(CACHE_DIR, "regles_contextuelles.json")
REGLES_STRUCTURELLES_PATH = os.path.join(CACHE_DIR, "regles_structurelles.json")

# Fichiers de donn√©es (JSON)
GLOSSAIRE_DISCLAIMERS_PATH = os.path.join(CACHE_DIR, "disclaimers.json")
FOND_REGISTRED_PATH_JSON = os.path.join(CACHE_DIR, "fond_registred.json")
GLOSSAIRES_JSON_PATH = os.path.join(CACHE_DIR, "glossaires.json")

# Documents de test
TEST_DOCUMENT_PATH = os.path.join(BASE_DIR, "tests")



# ====================  API CONFIGURATION ====================

# IMPORTANT: En production, utiliser des variables d'environnement
# Pour l'instant, valeurs fix√©es dans le code comme demand√©

LLAMA_API_KEY = "YOUR_API_KEY"
LLAMA_BASE_URL = "https://tokenfactory.esprit.tn/api"
LLAMA_MODEL = "hosted_vllm/Llama-3.1-70B-Instruct"


# ====================  PARAM√àTRES LLM ====================

LLM_TEMPERATURE = 0.1  # Temp√©rature basse pour plus de d√©terminisme
LLM_MAX_TOKENS = 4000
LLM_TOP_P = 0.9
LLM_FREQUENCY_PENALTY = 0.1
LLM_PRESENCE_PENALTY = 0.1


# ====================  PARAM√àTRES OCR ====================

OCR_LANGUAGES = "fra+eng"  # Tesseract langues
OCR_CONFIG = r'--oem 3 --psm 6'
OCR_LANGUAGES = "fra+eng"  # Tesseract langues
OCR_CONFIG = r'--oem 3 --psm 6'
OCR_MIN_CONFIDENCE = 0.5  # Confiance minimale pour accepter le texte
ENABLE_OCR = False  # Toggle pour activer/d√©sactiver l'OCR (True = traite images, False = ignore)


# ====================  PARAM√àTRES CHUNKING ====================

CHUNK_SIZE = 600  # Taille des chunks (r√©duit de 800 √† 600)
CHUNK_OVERLAP = 200  # Overlap entre chunks (augment√© de 150 √† 200)


# ====================  SEUILS DE SIMILARIT√â ====================

# Pour checker.py - Seuils CORRIG√âS (plus stricts)
SIMILARITY_THRESHOLD_STRICT = 0.7  # Threshold strict pour validation
SIMILARITY_THRESHOLD_FLEXIBLE = 0.4  # Threshold flexible pour recherche

# Pour dis_glos.py - Scores composites
DISCLAIMER_ALIGNMENT_THRESHOLD = 0.5  # Augment√© de 0.3 √† 0.5
LLM_SCORE_THRESHOLD = 7  # Score LLM minimum (sur 10) - augment√© de 5 √† 7


# ====================  PARAM√àTRES BATCH PROCESSING ====================

# Pour theorist.py
BATCH_SIZE = 5  # Nombre d'√©l√©ments par batch
PROCESS_ALL_ELEMENTS = True  # Ne PAS limiter le nombre de batchs (traiter TOUS les √©l√©ments)


# ====================  PARAM√àTRES M√âTRIQUES ====================

# M√©triques de validation
MIN_ANSWER_LENGTH = 20  # Longueur minimale d'une r√©ponse valide (augment√© de 5 √† 20)


# ====================  PARAM√àTRES DE CACHE ====================

CACHE_ENABLED = True
CACHE_TTL = 3600  # Time-to-live en secondes (1 heure)
CACHE_MAX_SIZE = 1000  # Nombre maximum d'entr√©es


# ====================  LOGGING ====================

LOG_LEVEL = "INFO"  # DEBUG, INFO, WARNING, ERROR
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
LOG_FILE_MAX_BYTES = 10 * 1024 * 1024  # 10 MB
LOG_FILE_BACKUP_COUNT = 5


# ====================  PROMPTS G√âN√âRAUX (NON ODDO-SP√âCIFIQUES) ====================

SYSTEM_PROMPT_DOCUMENT_ANALYSIS = """Tu es un expert en analyse de conformit√© documentaire g√©n√©rale.
Tu analyses des structures de documents et identifies les √©l√©ments √† v√©rifier selon des r√®gles de conformit√©.
Tu retournes UNIQUEMENT du JSON valide sans commentaires suppl√©mentaires.

Tes analyses doivent √™tre:
1. Bas√©es uniquement sur les r√®gles fournies
2. Pr√©cises et v√©rifiables
3. Applicables √† tout type de document financier
4. Structur√©es et coh√©rentes"""

SYSTEM_PROMPT_ALIGNMENT_CHECK = """Tu es un assistant expert en v√©rification d'alignement de documents.
Tu compares deux versions d'un m√™me document et identifies les diff√©rences importantes.

Tes r√©ponses doivent:
1. Identifier les incoh√©rences de contenu (hors langue et date)
2. Signaler les diff√©rences de donn√©es chiffr√©es
3. √ätre factuelles et bas√©es sur les textes fournis
4. Suivre le format demand√© strictement"""

SYSTEM_PROMPT_DISCLAIMER_GLOSSARY = """Tu es un assistant expert en analyse de disclaimers et glossaires.
Tu v√©rifies la conformit√© des mentions l√©gales et la coh√©rence des termes techniques.

Format de r√©ponse attendu:
- Pour les v√©rifications: [STATUT] - [RAISON]
- Pour les extractions: Liste claire et structur√©e
- Pour les analyses: Score suivi d'une justification br√®ve"""


# ====================  CR√âATION AUTOMATIQUE DES DOSSIERS ====================

def create_directories():
    """Cr√©e les dossiers n√©cessaires s'ils n'existent pas"""
    dirs = [OUTPUT_DIR, LOGS_DIR]
    for directory in dirs:
        os.makedirs(directory, exist_ok=True)
    print(f"‚úÖ Dossiers cr√©√©s: {dirs}")


#if __name__ == "__main__":
#    print("=" * 70)
#    print("‚öôÔ∏è  CONFIGURATION DU SYST√àME")
#    print("=" * 70)
#    
#    print(f"\nüìÅ Chemins configur√©s:")
#    print(f"  ‚Ä¢ R√®gles contextuelles: {REGLES_CONTEXTUELLES_PATH}")
#    print(f"  ‚Ä¢ R√®gles structurelles: {REGLES_STRUCTURELLES_PATH}")
#    print(f"  ‚Ä¢ Glossaire: {GLOSSAIRE_DISCLAIMERS_PATH}")
#    print(f"  ‚Ä¢ Registration abroad: {REGISTRATION_ABROAD_PATH}")
#    
#    print(f"\nü§ñ Configuration LLM:")
#    print(f"  ‚Ä¢ Mod√®le: {LLAMA_MODEL}")
#    print(f"  ‚Ä¢ Temp√©rature: {LLM_TEMPERATURE}")
#    print(f"  ‚Ä¢ Max tokens: {LLM_MAX_TOKENS}")
#    
#    print(f"\nüìä Param√®tres:")
#    print(f"  ‚Ä¢ Chunk size: {CHUNK_SIZE}")
#    print(f"  ‚Ä¢ Chunk overlap: {CHUNK_OVERLAP}")
#    print(f"  ‚Ä¢ Similarity threshold: {SIMILARITY_THRESHOLD_STRICT}")
#    print(f"  ‚Ä¢ Batch size: {BATCH_SIZE}")
#    
#    print(f"\nüìÇ Cr√©ation des dossiers...")
#    create_directories()
#    
#    print("\n" + "=" * 70)
#    print("‚úÖ CONFIGURATION CHARG√âE")
#    print("=" * 70)


# ==================== PROMPTS THEORIST ====================

THEORIST_ANALYSIS_PROMPT = """
ANALYSE S√âMANTIQUE ET CONFORMIT√â APPROFONDIE

Tu es un expert en conformit√© financi√®re et analyse s√©mantique.
Ton objectif est de v√©rifier la coh√©rence, la qualit√© r√©dactionnelle et le respect strict des r√®gles.

=== CONTEXTE DOCUMENTAIRE ===
Type: {doc_type}
M√©tadonn√©es: {metadata}

=== R√àGLES √Ä V√âRIFIER ===
{rules_context}

=== CONTENU DU DOCUMENT (Extrait structur√©) ===
{doc_content}

=== T√ÇCHE : GRAPHE S√âMANTIQUE & CONFORMIT√â ===
Analyse ce contenu en simulant un graphe conceptuel pour d√©tecter les incoh√©rences.

1. **Analyse S√©mantique & R√©daction** :
   - Qualit√© du langage (Ton professionnel, clart√©).
   - **Lexique** : D√©tecte TOUS les anglicismes non traduits (ex: "Track record" au lieu de "Historique").
   - **Coh√©rence** : Est-ce que les informations se contredisent ? (ex: "Risque faible" page 1 vs "Volatilit√© √©lev√©e" page 5).

2. **V√©rification des R√®gles (Deep Dive)** :
   - Pour chaque r√®gle fournie, v√©rifie si elle est respect√©e.
   - Cite PRECISEMENT l'ID de l'√©l√©ment (ex: slide_1_shape_2) pour chaque preuve.

=== FORMAT DE R√âPONSE JSON ===
R√©ponds UNIQUEMENT en JSON :
{{
  "semantic_analysis": {{
    "consistency_score": 85, // 0-100
    "drafting_score": 90, // 0-100
    "lexical_score": 95, // 0-100
    "anglicisms_detected": ["track record", "benchmark"],
    "inconsistencies": [
      {{"description": "Contradiction risque", "location_1": "slide_1...", "location_2": "slide_5..."}}
    ]
  }},
  "compliance_details": [
    {{
      "rule_id": "RC1",
      "status": "compliant|non_compliant",
      "evidence": "Le disclaimer est pr√©sent...",
      "location": "slide_1_shape_5",
      "confidence": 0.95
    }}
  ],
  "global_assessment": {{
    "risk_level": "low|medium|high",
    "summary": "Document coh√©rent mais quelques anglicismes..."
  }}
}}
"""
CHECKER_VERIFY_ALIGNMENT_PROMPT = """
Tu es un auditeur de conformit√©. Tu dois v√©rifier si une pr√©sentation (Target) est align√©e avec un document de r√©f√©rence, en r√©pondant √† une question sp√©cifique.

QUESTION: {question}

R√âPONSE ATTENDUE (Selon R√©f√©rence): {expected_answer}

CONTENU PERTINENT DE LA PR√âSENTATION (Target):
{context}

T√ÇCHE:
1. Cherche la r√©ponse √† la question dans le contenu pertinent de la pr√©sentation.
2. Compare cette r√©ponse avec la r√©ponse attendue.
3. D√©termine le niveau d'alignement.

G√©n√®re 3 versions de r√©ponse :
- Conservatrice : Strictement bas√©e sur le texte fourni.
- √âquilibr√©e : Synth√©tique et contextuelle.
- Cr√©ative : D√©duit les implications (sans inventer).

Ensuite, choisis la MEILLEURE r√©ponse qui repr√©sente fid√®lement le contenu de la pr√©sentation.

Format de sortie JSON attendu:
{{
  "actual_answer": "La pr√©sentation mentionne que...",
  "justification": "Trouv√© dans la slide X...",
  "alignment_status": "aligned|partial|misaligned|missing",
  "confidence": 0.9
}}
"""
